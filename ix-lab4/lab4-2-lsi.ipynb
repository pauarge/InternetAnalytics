{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *O*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Argelaguet Franquelo, Pau*\n",
    "* *du Bois de Dunilac, Vivien*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import SnowballStemmer\n",
    "from functools import reduce\n",
    "\n",
    "from utils import load_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = load_pkl(\"data/preprocess.pckl\")\n",
    "mat = load_pkl(\"data/mat.pckl\")\n",
    "terms = load_pkl(\"data/terms.pckl\")\n",
    "documents = load_pkl(\"data/documents.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting SVD for term-document matrix\n",
    "u, s, vt = svds(mat, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      "[[ 4.75531425e-04 -1.42264743e-03  3.48438305e-04 ...  1.59905513e-04\n",
      "  -3.75918352e-04  3.47056934e-04]\n",
      " [ 6.63699584e-03  7.40679389e-05 -9.91013840e-03 ...  3.67202019e-04\n",
      "  -6.91237574e-04  1.23154955e-03]\n",
      " [ 4.43642287e-04 -1.08911005e-03 -1.09324994e-03 ... -3.45563402e-04\n",
      "   2.20083864e-04  4.84372219e-04]\n",
      " ...\n",
      " [-4.86839273e-03 -1.39770492e-03  2.67787422e-03 ... -7.86812776e-04\n",
      "   8.20777860e-04  1.01081548e-03]\n",
      " [-4.86839273e-03 -1.39770492e-03  2.67787422e-03 ... -7.86812776e-04\n",
      "   8.20777860e-04  1.01081548e-03]\n",
      " [ 1.56029753e-02 -1.52466702e-03 -2.91512182e-03 ...  2.30137649e-03\n",
      "  -4.33040952e-03  5.62151557e-03]]\n",
      "\n",
      "S:\n",
      "[10.21018259 10.22389056 10.22764907 10.24104833 10.26100639 10.27784965\n",
      " 10.30843079 10.31586493 10.32829224 10.34992689 10.35682613 10.3707739\n",
      " 10.39050684 10.41472023 10.42579165 10.44747449 10.45200045 10.46057364\n",
      " 10.49742753 10.51434788 10.54982812 10.56413699 10.56554248 10.57418803\n",
      " 10.58232244 10.60515192 10.61121034 10.61761854 10.6535142  10.6703359\n",
      " 10.68609084 10.70126717 10.7302037  10.77086727 10.78102828 10.78778076\n",
      " 10.81283455 10.82038055 10.85095093 10.85835867 10.87183014 10.91635386\n",
      " 10.92308718 10.93868483 10.95322758 10.97155687 10.99781124 11.01341618\n",
      " 11.01608611 11.03592731 11.07123836 11.0857575  11.11587202 11.12018838\n",
      " 11.14209118 11.16234781 11.17490398 11.19750628 11.22201047 11.25088847\n",
      " 11.2542764  11.27732354 11.29240228 11.31177583 11.32400315 11.35253629\n",
      " 11.37287767 11.37923225 11.38924389 11.41254631 11.43711821 11.45497363\n",
      " 11.46978838 11.48177232 11.51472187 11.53372616 11.56858643 11.58907089\n",
      " 11.60420978 11.62271018 11.6378541  11.66111303 11.66680746 11.7007032\n",
      " 11.71649405 11.74100746 11.75063864 11.77860694 11.79084061 11.82309666\n",
      " 11.85501173 11.87228437 11.90009842 11.92921221 11.94330857 11.94605631\n",
      " 11.98254842 11.99459502 12.00689118 12.0321504  12.06206433 12.06619176\n",
      " 12.08879855 12.12541694 12.14559902 12.16988971 12.20508325 12.2193617\n",
      " 12.23585853 12.25583709 12.28873758 12.29938368 12.33026348 12.35558705\n",
      " 12.3663288  12.37323365 12.40687119 12.41818816 12.43654123 12.4449242\n",
      " 12.47133108 12.49591898 12.53959182 12.57594395 12.59170071 12.61658011\n",
      " 12.62806998 12.66711703 12.6854321  12.71026475 12.71399399 12.75896257\n",
      " 12.79045344 12.83405889 12.8644628  12.88161557 12.89030128 12.89941184\n",
      " 12.93811187 12.95092318 12.95922139 12.97266162 13.00377835 13.03681203\n",
      " 13.06902105 13.08875798 13.10986454 13.12656252 13.14461527 13.1911406\n",
      " 13.19912044 13.24695361 13.27110695 13.29981796 13.33018583 13.33579727\n",
      " 13.36753727 13.39691492 13.43231658 13.46592148 13.49294719 13.512866\n",
      " 13.5175957  13.57697089 13.60585038 13.62585236 13.65623548 13.67095917\n",
      " 13.71969821 13.72592272 13.7799793  13.79760541 13.83891503 13.8526723\n",
      " 13.87995097 13.90191801 13.92808956 13.99247149 14.02561002 14.03755629\n",
      " 14.06402611 14.11792834 14.13583445 14.17390977 14.19801897 14.25382173\n",
      " 14.28499367 14.31697041 14.34525175 14.37935693 14.3880801  14.42353157\n",
      " 14.43871126 14.46293502 14.49213732 14.54660608 14.55833556 14.59172615\n",
      " 14.63083473 14.66777532 14.70908973 14.71106156 14.73493055 14.80295173\n",
      " 14.81634245 14.84057821 14.84631007 14.92334768 14.9546202  14.9874814\n",
      " 15.0408221  15.06917214 15.10846905 15.11613988 15.20260288 15.21743725\n",
      " 15.22462106 15.27805269 15.3280477  15.34353202 15.43177476 15.48652532\n",
      " 15.49658714 15.51522099 15.56962234 15.6393012  15.65714226 15.68894985\n",
      " 15.73209062 15.75172511 15.79470832 15.86066083 15.90705197 15.97800333\n",
      " 16.00568544 16.01853622 16.0987259  16.16172114 16.21539576 16.2346094\n",
      " 16.28406747 16.33370337 16.38829349 16.45832236 16.5191332  16.57551386\n",
      " 16.61931749 16.67817941 16.70721746 16.7511339  16.80251235 16.90510662\n",
      " 16.98422884 17.0282103  17.06641455 17.18002183 17.24218611 17.29256906\n",
      " 17.34662032 17.467044   17.55178444 17.63685021 17.66127437 17.78291943\n",
      " 17.95456426 18.0022941  18.07827218 18.16115019 18.19832813 18.25495031\n",
      " 18.31047078 18.38102392 18.44163288 18.65313464 18.87406877 18.92663057\n",
      " 19.14941451 19.25276118 19.31229115 19.50511667 19.58978904 19.7164945\n",
      " 19.92779055 20.07054999 20.13074577 20.34157351 20.55123611 20.70861609\n",
      " 20.85078622 21.11478332 21.38088883 22.14025204 22.77778848 23.01309761\n",
      " 23.31041833 24.2899844  24.78481321 24.96998085 26.20523239 34.90169258]\n",
      "\n",
      "Vt:\n",
      "[[ 0.01136978  0.01716147  0.00709269 ...  0.0050475   0.04953265\n",
      "  -0.02939005]\n",
      " [ 0.02845908  0.02077848  0.01159254 ... -0.01512088 -0.03850066\n",
      "  -0.00230091]\n",
      " [-0.0229133  -0.00612376 -0.0051362  ...  0.0037048  -0.05419817\n",
      "  -0.00115468]\n",
      " ...\n",
      " [-0.02023883 -0.00499347 -0.08510143 ...  0.00415093  0.01638953\n",
      "   0.00835274]\n",
      " [ 0.00813131  0.00025674  0.04019882 ... -0.01024106 -0.00076336\n",
      "  -0.0143225 ]\n",
      " [ 0.03029372  0.00682784  0.05810659 ...  0.01259246  0.01615203\n",
      "   0.02253104]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"U:\\n{}\\n\".format(u))\n",
    "print(\"S:\\n{}\\n\".format(s))\n",
    "print(\"Vt:\\n{}\\n\".format(vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As any regular singular value decomposition, we have three matrices that come out decomposing X:\n",
    "\n",
    "* **U** is a matrix with columns representing concepts about terms, that is, each row is a term and the value is the weight of that term in the given concept.\n",
    "* **V** is similar to U but instead of relating concepts with terms, it relates them with documents. Note that we're using its transposed version, Vt.\n",
    "* **S** is a diagonal matrix of singular values, each one of which describe the importance of the given concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 eigenvalues of X:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1218.12814501,  686.71420463,  623.49994375,  614.28696605,\n",
       "        590.00334217,  543.37560286,  529.60266146,  518.82764824,\n",
       "        490.19076036,  457.1424072 ,  445.83407473,  434.75528609,\n",
       "        428.84678037,  422.35330548,  413.77961282,  405.24692545,\n",
       "        402.82697685,  397.11683637,  388.74015526,  383.75983474])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals = np.power(s, 2)[::-1][:20]\n",
    "print(\"Top-20 eigenvalues of X:\")\n",
    "eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 1 \n",
      "=====\n",
      "Terms:\n",
      " ['data', 'problem', 'evalu', 'report', 'skill', 'comput', 'electron', 'cell', 'studi', 'scientif', 'research', 'engin', 'mechan', 'plan', 'applic']\n",
      "Documents:\n",
      " ['Advanced materials for photovoltaics and lighting', 'Lab immersion III', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'History of globalization I', 'Lab immersion I', 'Project in bioengineering and biosciences', 'Philosophy of life sciences I', 'Cellular biology and biochemistry for engineers', 'Bioprocesses and downstream processing', 'Principles of finance', 'Experimental biochemistry and biophysics', \"CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It'\", 'Quantitative methods in finance', 'Particle-based methods', 'Nanobiotechnology and biophysics']\n",
      "\n",
      "\n",
      "Dimension 2 \n",
      "=====\n",
      "Terms:\n",
      " ['data', 'financi', 'financ', 'price', 'skill', 'risk', 'plan', 'evalu', 'optim', 'valuat', 'experiment', 'problem', 'corpor', 'market', 'scientif']\n",
      "Documents:\n",
      " ['Principles of finance', 'Lab immersion III', 'Introduction to finance (IF master and minor only)', 'Lab immersion I', 'Quantitative methods in finance', 'Project in bioengineering and biosciences', 'Lab immersion II', 'Semester project in Bioengineering', 'Derivatives', 'Martingales in financial mathematics', 'Financial econometrics', 'Advanced topics in financial econometrics', 'Investments', 'Philosophy of life sciences I', 'Macrofinance']\n",
      "\n",
      "\n",
      "Dimension 3 \n",
      "=====\n",
      "Terms:\n",
      " ['price', 'financi', 'financ', 'risk', 'stochast', 'valuat', 'deriv', 'market', 'option', 'corpor', 'equat', 'asset', 'probabl', 'corpor financ', 'capit']\n",
      "Documents:\n",
      " ['Principles of finance', 'Quantitative methods in finance', 'Introduction to finance (IF master and minor only)', 'Martingales in financial mathematics', 'Derivatives', 'Advanced materials for photovoltaics and lighting', 'Advanced topics in financial econometrics', 'Investments', 'Stochastic calculus I', 'Financial econometrics', 'Computational finance', \"Numerical approximation of PDE's II\", 'Fixed income analysis', 'Venture capital', 'Sparse stochastic processes']\n",
      "\n",
      "\n",
      "Dimension 4 \n",
      "=====\n",
      "Terms:\n",
      " ['solar cell', 'solar', 'cell', 'emit', 'light emit', 'dyesensit solar', 'excit state', 'dyesensit', 'sensit', 'excit', 'hour week', 'case', 'studi', 'direct', 'case studi']\n",
      "Documents:\n",
      " ['Advanced materials for photovoltaics and lighting', 'Lab immersion III', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Lab immersion I', 'Principles of finance', 'Introduction to finance (IF master and minor only)', 'History of globalization I', 'Project in bioengineering and biosciences', 'Lab immersion in industry A', 'Lab immersion in industry B', 'Lab immersion academic (outside EPFL) B', 'Lab immersion academic (outside EPFL) A', 'Lab immersion II', 'Semester project in Bioengineering', 'Experimental cognitive psychology I']\n",
      "\n",
      "\n",
      "Dimension 5 \n",
      "=====\n",
      "Terms:\n",
      " ['imag', 'equat', 'electron', 'numer', 'linear', 'optic', 'flow', 'algorithm', 'comput', 'mechan', 'devic', 'differenti', 'signal', 'fluid', 'sensor']\n",
      "Documents:\n",
      " [\"Numerical approximation of PDE's II\", 'Particle-based methods', 'Numerical methods in heat transfer', 'Sparse stochastic processes', 'Scanning electron microscopy techniques (b)', 'Scanning electron microscopy techniques (a)', 'Introduction to scanning electron microscopy microanalysis techniques', 'Nanobiotechnology and biophysics', 'Unsupervised and reinforcement learning in neural networks', '1st Workshop on Advances in CFD and MD modelling of Interface Dynamics in Capillary Two-Phase Flows', 'Photomechanics for Engineers', 'Numerical methods for electromagnetics', 'Advanced numerical analysis', 'Numerical methods in biomechanics', 'Numerical methods in chemistry']\n",
      "\n",
      "\n",
      "Dimension 6 \n",
      "=====\n",
      "Terms:\n",
      " ['problem', 'linear', 'data', 'numer', 'experiment', 'equat', 'optim', 'wetlab', 'obtain', 'algorithm', 'scientif', 'report', 'statist', 'transvers skill', 'transvers']\n",
      "Documents:\n",
      " ['Advanced materials for photovoltaics and lighting', 'Lab immersion III', \"Numerical approximation of PDE's II\", 'Lab immersion I', \"CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It'\", 'Project in bioengineering and biosciences', 'Lab immersion II', 'Semester project in Bioengineering', 'Particle-based methods', 'Numerical methods for electromagnetics', 'Pattern classification and machine learning', 'Fundamentals in statistical pattern recognition', 'Advanced numerical analysis', 'Lab immersion in industry A', 'Unsupervised and reinforcement learning in neural networks']\n",
      "\n",
      "\n",
      "Dimension 7 \n",
      "=====\n",
      "Terms:\n",
      " ['imag', 'electron', 'protein', 'experiment', 'microscopi', 'optic', 'financi', 'financ', 'molecular', 'risk', 'skill', 'scientif', 'cell', 'spectroscopi', 'biophys']\n",
      "Documents:\n",
      " ['Nanobiotechnology and biophysics', 'Lab immersion III', 'Principles of finance', 'Experimental biochemistry and biophysics', 'Lab immersion I', 'Introduction to finance (IF master and minor only)', 'Scanning electron microscopy techniques (a)', 'Scanning electron microscopy techniques (b)', 'Introduction to scanning electron microscopy microanalysis techniques', 'Chemistry of small biological molecules', 'Project in bioengineering and biosciences', 'Lab immersion II', 'Semester project in Bioengineering', 'Analysis of ancient materials and their degradation', 'Nanofabrication with focused electron and ion beams']\n",
      "\n",
      "\n",
      "Dimension 8 \n",
      "=====\n",
      "Terms:\n",
      " ['equat', 'flow', 'engin', 'mechan', 'numer', 'fluid', 'chemic', 'kinet', 'reaction', 'heat', 'reactor', 'bioprocess', 'transfer', 'chemistri', 'energi']\n",
      "Documents:\n",
      " ['Bioprocesses and downstream processing', 'Biochemical engineering', 'CCMX Advanced Course - Inorganic Particle Synthesis by Precipitation: From Nanoparticles to Self-organised  Mesocrystals and from Theory to Practice', 'Particle-based methods', 'Numerical methods in heat transfer', 'Reservoir mechanics for geo-energy and the environment', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Leading research in Chemical Engineering (b)', 'Leading research in Chemical Engineering (a)', 'Chemical thermodynamics', 'Numerical methods in biomechanics', 'Recent Events in Energy-1', 'Engineering geology for geo-energy', 'Introduction to chemical engineering', 'Instability']\n",
      "\n",
      "\n",
      "Dimension 9 \n",
      "=====\n",
      "Terms:\n",
      " ['electron', 'devic', 'circuit', 'semiconductor', 'properti', 'transistor', 'optic', 'technolog', 'electr', 'cmos', 'skill', 'energi', 'quantum', 'transfer', 'report']\n",
      "Documents:\n",
      " ['MINTT: Management of Innovation and technology transfer (EDOC)', 'Microelectronics', 'Lab immersion III', 'Photochemistry II', 'Semiconductor physics and fundamentals of electronic devices', 'Lab immersion I', 'Large-area electronics: devices and materials', 'Nanoscale MOSFETs and beyond CMOS devices', 'Nanoelectronics', 'Optical detectors', 'IEEE Sensors Council Summer School on Nano-Bio-Sensing', 'Solid state physics II', '2D Layered Materials: Synthesis, Properties and Applications', 'Flexible bioelectronics', 'Solid state image sensing']\n",
      "\n",
      "\n",
      "Dimension 10 \n",
      "=====\n",
      "Terms:\n",
      " ['statist', 'linear', 'regress', 'energi', 'chemistri', 'probabl', 'reactor', 'machin', 'reaction', 'seminar', 'algebra', 'field', 'network', 'nuclear', 'machin learn']\n",
      "Documents:\n",
      " ['Unsupervised and reinforcement learning in neural networks', 'Frederic Joliot/Otto Hahn Summer School on nuclear reactors Physics, fuels and systems', 'Fundamentals in statistical pattern recognition', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Pattern classification and machine learning', 'Recent Events in Energy-1', 'Philosophy of life sciences I', 'Recent Events in Energy-2', 'Statistical Sequence Processing', 'Leading research in Chemical Engineering (b)', 'Leading research in Chemical Engineering (a)', 'Machine Learning for Engineers', 'Advanced machine learning', 'Biostatistics', 'Experimental design and data analysis with R']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take the top 10 concepts (the ones with highest singular value) from u and from v\n",
    "top_u = u.T[::-1][:10]\n",
    "top_v = vt[::-1][:10]\n",
    "\n",
    "# For each concept, get the 15 terms and documents with highest value, that is, the one that have most influence on each of them\n",
    "for i, (t, d) in enumerate(zip(top_u, top_v)):\n",
    "    ts = map(lambda x: terms[x], t.argsort()[::-1][:15])\n",
    "    ds = map(lambda x: dat[documents[x]]['name'], d.argsort()[::-1][:15])\n",
    "    print(\"Dimension\", i + 1, \"\\n=====\")\n",
    "    print(\"Terms:\\n\", list(ts))\n",
    "    print(\"Documents:\\n\", list(ds))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Life sciences\n",
    "\n",
    "1. Finance\n",
    "\n",
    "2. Mathematical finance\n",
    "\n",
    "3. Algorithms\n",
    "\n",
    "4. Biology\n",
    "\n",
    "5. Imaging\n",
    "\n",
    "6. Laboratory\n",
    "\n",
    "7. Chemistry\n",
    "\n",
    "8. Energy\n",
    "\n",
    "9. Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning s (vector) into S (diagonal matrix)\n",
    "S = np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comupte similarity between two vectors using the provided formula\n",
    "def compute_sim(ut, vd):\n",
    "    return np.dot(ut, S.dot(vd)) / (np.linalg.norm(ut) * np.linalg.norm(S.dot(vd)))\n",
    "\n",
    "\n",
    "# Get document similar to a text \n",
    "def search(t):\n",
    "    # Splitting and stemming input text into words\n",
    "    search_terms = list(map(stemmer.stem, t.split()))\n",
    "    bigrams = list(map(lambda x: x[0] + \" \" + x[1], zip(search_terms, search_terms[1:])))\n",
    "    search_terms = search_terms + bigrams\n",
    "    \n",
    "    # Constructing q vector, using U weights of all its terms\n",
    "    q = sum(map(lambda x: u[terms.index(x)], search_terms))\n",
    "    \n",
    "    # Computing similarities of all columns (documents) with given query\n",
    "    sims = [compute_sim(q, d) for d in vt.T]\n",
    "    sims = {dat[documents[i]]['name']: x for i, x in enumerate(sims) if x > 0}  \n",
    "    sims = sorted(sims.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for markov chains:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Applied stochastic processes', 0.8493125140393682),\n",
       " ('Applied probability & stochastic processes', 0.7683334599633568),\n",
       " ('Markov chains and algorithmic applications', 0.7062631524329015),\n",
       " ('Supply chain management', 0.3643857150073063),\n",
       " ('Mathematical models in supply chain management', 0.33746631152875783)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 5 courses for markov chains:\")\n",
    "search('markov chains')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for facebook:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computational Social Media', 0.9616706165470982),\n",
       " ('Social media', 0.8789927989448072),\n",
       " ('Media security', 0.28832855429967114),\n",
       " ('Networks out of control', 0.21226715753443506),\n",
       " ('Advanced principles and applications of systems biology',\n",
       "  0.19201882496768302)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 5 courses for facebook:\")\n",
    "search('facebook')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For markov chains, we can see that we get similar results as previous part, but with different scores. With facebook though, we see that now we get more than one result. In both cases, that is because we're no longer using explicit words but the concepts they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate document-document similarity, we simply take the existing representation of documents as a vectors and comute their cosine similarity. Then, we sort similarities to get the most similar documents to IX course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_sim(d1, d2):\n",
    "    d1S = S.dot(d1)\n",
    "    d2S = S.dot(d2)\n",
    "    return d1S.dot(d2S) / (np.linalg.norm(d1S) * np.linalg.norm(d2S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents.index('COM-308')\n",
    "\n",
    "v = vt.T\n",
    "\n",
    "sims = [compute_doc_sim(v[doc], d) for d in v]\n",
    "sims = {dat[documents[i]]['name']: x for i, x in enumerate(sims) if x > 0}  \n",
    "sims = sorted(sims.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top classes similar to Internet Analytics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Internet analytics', 1.0),\n",
       " ('Distributed information systems', 0.41504065554504316),\n",
       " ('Applied data analysis', 0.3982774061444288),\n",
       " ('A Network Tour of Data Science', 0.39332022400583666),\n",
       " ('Digital education & learning analytics', 0.3259200480581976),\n",
       " ('Financial big data', 0.32077327378292825)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top classes similar to Internet Analytics:\")\n",
    "sims[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
