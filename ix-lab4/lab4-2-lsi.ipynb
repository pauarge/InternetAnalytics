{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *O*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Argelaguet Franquelo, Pau*\n",
    "* *du Bois de Dunilac, Vivien*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import SnowballStemmer\n",
    "from functools import reduce\n",
    "\n",
    "from utils import load_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = load_pkl(\"data/preprocess.pckl\")\n",
    "mat = load_pkl(\"data/mat.pckl\")\n",
    "terms = load_pkl(\"data/terms.pckl\")\n",
    "documents = load_pkl(\"data/documents.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting SVD for term-document matrix\n",
    "u, s, vt = svds(mat, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      "[[-9.68887812e-04  8.98294797e-04  2.00651142e-03 ... -2.11339226e-04\n",
      "  -2.55484042e-04  3.82873645e-04]\n",
      " [ 4.39596334e-04 -8.23695943e-03 -2.64177604e-03 ... -1.29299593e-03\n",
      "  -1.46493875e-03  1.41270066e-03]\n",
      " [ 8.08574020e-04 -2.08109150e-03  5.79369170e-05 ...  5.52254194e-04\n",
      "   2.55659605e-04  5.37726825e-04]\n",
      " ...\n",
      " [-1.24180018e-02  6.16235786e-03  2.26840193e-02 ... -1.75524500e-03\n",
      "  -7.41692901e-03  5.03089230e-03]\n",
      " [ 6.24752249e-04  2.15742698e-03 -2.67469022e-04 ...  1.92618739e-03\n",
      "   1.07799377e-03  1.12821616e-03]\n",
      " [-1.53190533e-03  1.08578184e-03  7.50685750e-03 ... -4.77854170e-03\n",
      "  -4.83765771e-03  5.71071883e-03]]\n",
      "\n",
      "S:\n",
      "[ 8.26214376  8.29163895  8.31116009  8.31141847  8.32749439  8.35467656\n",
      "  8.36125285  8.38857632  8.4073862   8.42911247  8.43873641  8.45066588\n",
      "  8.45416843  8.47028827  8.49684213  8.52436349  8.5279323   8.53262854\n",
      "  8.5600703   8.5887046   8.59097322  8.59880867  8.62884505  8.64518168\n",
      "  8.65053714  8.6575309   8.68010666  8.69884119  8.70434363  8.71815994\n",
      "  8.75103653  8.76308529  8.77734154  8.78567718  8.81048461  8.83962252\n",
      "  8.84162677  8.86337576  8.87920555  8.89447398  8.90216498  8.90779442\n",
      "  8.9260756   8.93551423  8.9418822   8.96467847  8.98435756  9.00269077\n",
      "  9.01976738  9.02178975  9.05299736  9.06696196  9.08538851  9.10198858\n",
      "  9.12769552  9.14982312  9.1602421   9.17160914  9.21833292  9.22264796\n",
      "  9.23433405  9.24659966  9.26841081  9.30220588  9.31316159  9.34113006\n",
      "  9.35999774  9.37385665  9.39506009  9.40755789  9.41310382  9.41484431\n",
      "  9.45697775  9.46968244  9.49072747  9.51845173  9.5407372   9.55228969\n",
      "  9.55617622  9.58502449  9.59199293  9.60842709  9.63163216  9.65467211\n",
      "  9.67255521  9.68801919  9.70773822  9.73905247  9.76007751  9.77981757\n",
      "  9.80856267  9.82330313  9.85531198  9.86251686  9.87384845  9.90192699\n",
      "  9.93338787  9.94492571  9.9690382   9.98311965 10.00530071 10.02514826\n",
      " 10.05178236 10.06703234 10.09950797 10.10634946 10.12918692 10.13591048\n",
      " 10.17508692 10.18974383 10.21925038 10.22905668 10.26515297 10.30146065\n",
      " 10.31099312 10.33541363 10.35454074 10.38707393 10.3973343  10.44317186\n",
      " 10.46145333 10.49418093 10.5042919  10.53448063 10.55827651 10.5790344\n",
      " 10.61102171 10.61677686 10.63011029 10.66286865 10.67893855 10.70276778\n",
      " 10.71574435 10.75152968 10.76006848 10.76407919 10.78108191 10.81701787\n",
      " 10.83996458 10.8618663  10.92217837 10.96677096 10.97400596 11.01175977\n",
      " 11.03126935 11.03976066 11.06170779 11.09791694 11.11349476 11.14516176\n",
      " 11.15980197 11.22741666 11.24521522 11.2666397  11.28073825 11.28966207\n",
      " 11.33209629 11.34141824 11.36588711 11.42525274 11.44298358 11.44842577\n",
      " 11.48664105 11.49865331 11.51192349 11.54206241 11.54447636 11.60055093\n",
      " 11.62647647 11.68177341 11.70396982 11.73895876 11.77976417 11.80537715\n",
      " 11.82051161 11.82667972 11.85563035 11.88214704 11.9328543  11.94007936\n",
      " 11.97247522 11.97867161 12.03207684 12.09624946 12.11228168 12.1272666\n",
      " 12.14519461 12.20262875 12.22248896 12.27323273 12.28334077 12.331271\n",
      " 12.34758707 12.37499616 12.39651182 12.42284095 12.45296976 12.48799081\n",
      " 12.53114692 12.57804413 12.60478189 12.62489593 12.66111071 12.6869423\n",
      " 12.71466269 12.77406333 12.79568503 12.81712427 12.87738283 12.88782209\n",
      " 12.89427794 12.94336398 13.00919879 13.03058316 13.07513287 13.10996826\n",
      " 13.1329745  13.16841003 13.19464581 13.25714856 13.29044777 13.32465089\n",
      " 13.38100277 13.41712972 13.45141905 13.492798   13.54478574 13.56743973\n",
      " 13.62363755 13.6424766  13.72423497 13.73104272 13.76231083 13.81796998\n",
      " 13.86778821 13.93420782 13.96788365 14.01198123 14.04384546 14.07227279\n",
      " 14.15740793 14.17109151 14.25169008 14.31746902 14.34694516 14.37357689\n",
      " 14.41991498 14.47261264 14.56859495 14.62190465 14.64476274 14.74806131\n",
      " 14.80376403 14.8285026  14.84514843 14.86094651 14.91155272 15.03359501\n",
      " 15.07303151 15.13405904 15.17454524 15.2770198  15.31695255 15.3605892\n",
      " 15.46506318 15.53440158 15.58422866 15.78219482 15.82085287 15.84620521\n",
      " 15.93994999 15.99719027 16.037453   16.3195875  16.45212057 16.48449711\n",
      " 16.5486863  16.71756946 16.81189354 16.86725783 17.15126183 17.25672473\n",
      " 17.4328386  17.48328824 17.79509686 17.97470792 18.11873992 18.28767693\n",
      " 18.46153591 18.61775949 18.71434841 19.20983842 19.37242677 20.24953573\n",
      " 21.06260796 21.33943475 21.51838237 22.82881421 23.70234395 33.4525684 ]\n",
      "\n",
      "Vt:\n",
      "[[-2.24476480e-02  5.62948732e-03 -1.05534615e-02 ... -8.32203894e-03\n",
      "   1.02872297e-02  5.29855110e-03]\n",
      " [ 1.30195396e-01  3.50352533e-02 -1.44771446e-02 ...  7.74324090e-03\n",
      "  -9.95189143e-03 -2.42813763e-02]\n",
      " [ 3.23524744e-02  1.05519521e-04  1.45227894e-02 ...  1.73367141e-02\n",
      "   4.39974271e-02  5.29237926e-03]\n",
      " ...\n",
      " [ 4.62139931e-02  1.35592826e-02  1.81301287e-01 ... -5.01564708e-03\n",
      "  -2.35368379e-02 -1.65359902e-02]\n",
      " [ 1.31478139e-02  3.20311379e-03  5.34576972e-02 ... -6.29533111e-03\n",
      "  -2.68044238e-03 -1.78113507e-02]\n",
      " [ 3.26044950e-02  7.28759179e-03  6.28287474e-02 ...  1.33152230e-02\n",
      "   1.74049867e-02  2.47173730e-02]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"U:\\n{}\\n\".format(u))\n",
    "print(\"S:\\n{}\\n\".format(s))\n",
    "print(\"Vt:\\n{}\\n\".format(vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As any regular singular value decomposition, we have three matrices that come out decomposing X:\n",
    "\n",
    "* **U** is a matrix with columns representing concepts about terms, that is, each row is a term and the value is the weight of that term in the given concept.\n",
    "* **V** is similar to U but instead of relating concepts with terms, it relates them with documents. Note that we're using its transposed version, Vt.\n",
    "* **S** is a diagonal matrix of singular values, each one of which describe the importance of the given concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 eigenvalues of X:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1119.07433225,  561.80110877,  521.15475805,  463.04078001,\n",
       "        455.37147556,  443.63345395,  410.04369745,  375.29091879,\n",
       "        369.017892  ,  350.22683623,  346.62096847,  340.8283083 ,\n",
       "        334.4391275 ,  328.28873629,  323.09012486,  316.66547214,\n",
       "        305.6653677 ,  303.90386152,  297.79454853,  294.16578248])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals = np.power(s, 2)[::-1][:20]\n",
    "print(\"Top-20 eigenvalues of X:\")\n",
    "eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 1 \n",
      "=====\n",
      "Terms:\n",
      " ['data', 'problem', 'evalu', 'report', 'comput', 'electron', 'skill', 'mechan', 'research', 'engin', 'scientif', 'cell', 'discuss', 'plan', 'applic']\n",
      "Documents:\n",
      " ['Lab immersion III', 'Advanced materials for photovoltaics and lighting', 'Cellular biology and biochemistry for engineers', 'History of globalization I', 'Project in bioengineering and biosciences', 'Bioprocesses and downstream processing', 'Experimental biochemistry and biophysics', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Lab immersion I', 'Philosophy of life sciences I', 'Principles of finance', 'Nanobiotechnology and biophysics', 'Numerical methods in heat transfer', 'Quantitative methods in finance', 'Particle-based methods']\n",
      "\n",
      "\n",
      "Dimension 2 \n",
      "=====\n",
      "Terms:\n",
      " ['financi', 'financ', 'price', 'risk', 'valuat', 'data', 'market', 'corpor', 'stochast', 'option', 'capit', 'firm', 'deriv', 'manag', 'optim']\n",
      "Documents:\n",
      " ['Principles of finance', 'Introduction to finance (IF master and minor only)', 'Quantitative methods in finance', 'Derivatives', 'Martingales in financial mathematics', 'Financial econometrics', 'Advanced topics in financial econometrics', 'Investments', 'Lab immersion III', 'Macrofinance', 'Venture capital', 'Computational finance', 'Project in bioengineering and biosciences', 'Lab immersion I', 'Fixed income analysis']\n",
      "\n",
      "\n",
      "Dimension 3 \n",
      "=====\n",
      "Terms:\n",
      " ['semest', 'architectur', 'scientif', 'research', 'develop', 'urban', 'experiment', 'report', 'studio', 'plan', 'evalu', 'data', 'build', 'obtain', 'dure']\n",
      "Documents:\n",
      " ['Studio BA5 (FrÃ¶hlich M. & A.)', 'Lab immersion III', 'History of globalization I', 'Project in bioengineering and biosciences', 'ThÃ©orie et critique du projet MA1 (Huang)', 'Lab immersion I', 'ThÃ©orie et critique du projet MA2 (Gugger)', 'ThÃ©orie et critique du projet MA2 (Huang)', 'Studio MA1 (Escher et GuneWardena)', 'Experimental biochemistry and biophysics', 'Difficult Double Double Histories', 'ThÃ©orie et critique du projet MA1 (Gugger)', 'Lab immersion in industry A', 'Experimental cognitive psychology I', 'Lab immersion in industry B']\n",
      "\n",
      "\n",
      "Dimension 4 \n",
      "=====\n",
      "Terms:\n",
      " ['risk', 'financi', 'financ', 'valuat', 'corpor', 'cell', 'price', 'capit', 'firm', 'market', 'chemistri', 'manag', 'case', 'biolog', 'arbitrag']\n",
      "Documents:\n",
      " ['Principles of finance', 'Introduction to finance (IF master and minor only)', 'Bioprocesses and downstream processing', 'Venture capital', 'Biochemical engineering', 'Investments', 'Advanced materials for photovoltaics and lighting', 'Derivatives', 'Corporate strategy', 'Investing: a Guide to Doing the Right Thing', 'Quantitative methods in finance', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Fixed income analysis', 'Advanced topics in financial econometrics', 'Lab methods : biosafety']\n",
      "\n",
      "\n",
      "Dimension 5 \n",
      "=====\n",
      "Terms:\n",
      " ['architectur', 'studio', 'urban', 'devic', 'scale', 'build', 'circuit', 'electron', 'digit', 'berlin', 'typolog', 'site', 'semest', 'transistor', 'spatial']\n",
      "Documents:\n",
      " ['Studio BA5 (FrÃ¶hlich M. & A.)', 'ThÃ©orie et critique du projet MA1 (Huang)', 'ThÃ©orie et critique du projet MA2 (Huang)', 'ThÃ©orie et critique du projet MA1 (Gugger)', 'Studio MA1 (Escher et GuneWardena)', 'ThÃ©orie et critique du projet MA2 (Gugger)', 'Microelectronics', 'Studio MA2 (LÃ¼tjens et Padmanabhan)', 'Nanoscale MOSFETs and beyond CMOS devices', 'Wireless Transceivers: Radio Architectures, System and Circuit Design', 'Introduction to multiprocessor architecture', 'Studio MA1 (LÃ¼tjens et Padmanabhan)', 'Nanoelectronics', 'Optical detectors', 'ThÃ©orie et critique du projet BA3 (De Vylder & Taillieu)']\n",
      "\n",
      "\n",
      "Dimension 6 \n",
      "=====\n",
      "Terms:\n",
      " ['imag', 'optic', 'electron', 'sensor', 'microscopi', 'data', 'techniqu', 'experiment', 'spectroscopi', 'circuit', 'devic', 'sem', 'ccd', 'protein', 'signal']\n",
      "Documents:\n",
      " ['Nanobiotechnology and biophysics', 'Optical detectors', 'Solid state image sensing', 'Scanning electron microscopy techniques (a)', 'Scanning electron microscopy techniques (b)', 'Experimental biochemistry and biophysics', 'Lab immersion III', 'Analysis of ancient materials and their degradation', 'Photomechanics for Engineers', 'Introduction to scanning electron microscopy microanalysis techniques', 'Biomicroscopy II', 'Lab immersion I', 'Chemistry of small biological molecules', 'Image optics', 'Sensors in medical instrumentation']\n",
      "\n",
      "\n",
      "Dimension 7 \n",
      "=====\n",
      "Terms:\n",
      " ['devic', 'report', 'skill', 'electron', 'plan', 'experiment', 'circuit', 'wetlab', 'obtain', 'evalu', 'technolog', 'energi', 'electr', 'semiconductor', 'transvers']\n",
      "Documents:\n",
      " ['Lab immersion III', 'Lab immersion I', 'Project in bioengineering and biosciences', 'MINTT: Management of Innovation and technology transfer (EDOC)', 'Microelectronics', 'Semiconductor physics and fundamentals of electronic devices', 'Lab immersion II', 'Semester project in Bioengineering', 'Lab immersion in industry A', 'Lab immersion in industry B', 'Flexible bioelectronics', 'Lab immersion academic (outside EPFL) A', 'Lab immersion academic (outside EPFL) B', 'Frederic Joliot/Otto Hahn Summer School on nuclear reactors Physics, fuels and systems', 'Bioelectronics and implantable biomedical microelectronics']\n",
      "\n",
      "\n",
      "Dimension 8 \n",
      "=====\n",
      "Terms:\n",
      " ['chemistri', 'statist', 'reaction', 'seminar', 'regress', 'research', 'reactor', 'linear', 'probabl', 'organ', 'energi', 'synthesi', 'field', 'topic', 'seri']\n",
      "Documents:\n",
      " ['Frederic Joliot/Otto Hahn Summer School on nuclear reactors Physics, fuels and systems', 'Recent Events in Energy-1', 'Inorganic chemistry \"Applications and spin-offs\"', 'Recent Events in Energy-2', 'Frontiers in Organic Synthesis. Part III Stereochemistry', 'Fundamentals in statistical pattern recognition', 'Inorganic chemistry \"Techniques and methods\"', 'Pattern classification and machine learning', 'Frontiers in Organic Synthesis. Part II Synthesis of carbo- and hetero-cycles', \"CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It'\", 'Fate and behaviour of organic pollutants', 'Machine Learning for Engineers', 'Unsupervised and reinforcement learning in neural networks', 'Coordination chemistry and reactivity of f elements', 'Seminar series on advances in materials (spring)']\n",
      "\n",
      "\n",
      "Dimension 9 \n",
      "=====\n",
      "Terms:\n",
      " ['circuit', 'bioprocess', 'cell', 'bioreactor', 'kinet', 'control', 'analog', 'adsorpt', 'downstream', 'precipit', 'yield', 'power', 'data', 'product', 'dsp']\n",
      "Documents:\n",
      " ['Bioprocesses and downstream processing', 'Biochemical engineering', 'Microelectronics', 'CCMX Advanced Course - Inorganic Particle Synthesis by Precipitation: From Nanoparticles to Self-organised  Mesocrystals and from Theory to Practice', 'Analog circuits design II', 'Hardware systems modeling', 'Advanced lab in electrical energy systems', 'HF and VHF circuits and techniques I', 'Low-voltage analog CMOS IC design', 'Analog circuits design I', 'Analog circuits for biochip', 'HF and VHF circuits and techniques II', 'Nanoscale MOSFETs and beyond CMOS devices', 'Fundamentals of VLSI design', 'Advanced analog and RF integrated circuits design II']\n",
      "\n",
      "\n",
      "Dimension 10 \n",
      "=====\n",
      "Terms:\n",
      " ['imag', 'reactor', 'growth', 'alloy', 'bioprocess', 'precipit', 'sem', 'kinet', 'xray', 'solidif', 'nucleat', 'powder', 'bioreactor', 'engin', 'microscop']\n",
      "Documents:\n",
      " [\"CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It'\", 'CCMX Advanced Course - Inorganic Particle Synthesis by Precipitation: From Nanoparticles to Self-organised  Mesocrystals and from Theory to Practice', 'Bioprocesses and downstream processing', 'CCMX Winter School - Metal Science', 'Biochemical engineering', 'Analysis of ancient materials and their degradation', 'Scanning electron microscopy techniques (b)', 'Scanning electron microscopy techniques (a)', 'Introduction to scanning electron microscopy microanalysis techniques', 'Nanofabrication with focused electron and ion beams', 'Crystallography of structural phase transformations', 'ThÃ©orie et critique du projet MA1 (Huang)', 'ThÃ©orie et critique du projet MA2 (Huang)', 'Effects of radiation on materials', 'Thin film fabrication processes']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take the top 10 concepts (the ones with highest singular value) from u and from v\n",
    "top_u = u.T[::-1][:10]\n",
    "top_v = vt[::-1][:10]\n",
    "\n",
    "# For each concept, get the 15 terms and documents with highest value, that is, the one that have most influence on each of them\n",
    "for i, (t, d) in enumerate(zip(top_u, top_v)):\n",
    "    ts = map(lambda x: terms[x], t.argsort()[::-1][:15])\n",
    "    ds = map(lambda x: dat[documents[x]]['name'], d.argsort()[::-1][:15])\n",
    "    print(\"Dimension\", i + 1, \"\\n=====\")\n",
    "    print(\"Terms:\\n\", list(ts))\n",
    "    print(\"Documents:\\n\", list(ds))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Life sciences\n",
    "\n",
    "1. Finance\n",
    "\n",
    "2. Mathematical finance\n",
    "\n",
    "3. Algorithms\n",
    "\n",
    "4. Biology\n",
    "\n",
    "5. Imaging\n",
    "\n",
    "6. Laboratory\n",
    "\n",
    "7. Chemistry\n",
    "\n",
    "8. Energy\n",
    "\n",
    "9. Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning s (vector) into S (diagonal matrix)\n",
    "S = np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comupte similarity between two vectors using the provided formula\n",
    "def compute_sim(ut, vd):\n",
    "    return np.dot(ut, S.dot(vd)) / (np.linalg.norm(ut) * np.linalg.norm(S.dot(vd)))\n",
    "\n",
    "\n",
    "# Get document similar to a text \n",
    "def search(t):\n",
    "    # Splitting and stemming input text into words\n",
    "    search_terms = list(map(stemmer.stem, t.split()))\n",
    "    \n",
    "    # Constructing q vector, using U weights of all its terms\n",
    "    q = sum(map(lambda x: u[terms.index(x)], search_terms))\n",
    "    \n",
    "    # Computing similarities of all columns (documents) with given query\n",
    "    sims = [compute_sim(q, d) for d in vt.T]\n",
    "    sims = {dat[documents[i]]['name']: x for i, x in enumerate(sims) if x > 0}  \n",
    "    sims = sorted(sims.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for markov chains:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Applied stochastic processes', 0.8609327376522445),\n",
       " ('Applied probability & stochastic processes', 0.7771197541178925),\n",
       " ('Markov chains and algorithmic applications', 0.6557304950301164),\n",
       " ('Supply chain management', 0.5425899859425819),\n",
       " ('Statistical Sequence Processing', 0.4943533254452211)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 5 courses for markov chains:\")\n",
    "search('markov chains')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for facebook:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computational Social Media', 0.9351569084095054),\n",
       " ('Social media', 0.7693572030048721),\n",
       " ('Media security', 0.35814100943358684),\n",
       " ('Advanced principles and applications of systems biology',\n",
       "  0.2215975645614137),\n",
       " ('Image communication', 0.19981436592184496)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 5 courses for facebook:\")\n",
    "search('facebook')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For markov chains, we can see that we get similar results as previous part, but with different scores. With facebook though, we see that now we get more than one result. In both cases, that is because we're no longer using explicit words but the concepts they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_sim(d1, d2):\n",
    "    d1S = S.dot(d1)\n",
    "    d2S = S.dot(d2)\n",
    "    return d1S.dot(d2S) / (np.linalg.norm(d1S) * np.linalg.norm(d2S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents.index('COM-308')\n",
    "\n",
    "v = vt.T\n",
    "\n",
    "sims = [compute_doc_sim(v[doc], d) for d in v]\n",
    "sims = {dat[documents[i]]['name']: x for i, x in enumerate(sims) if x > 0}  \n",
    "sims = sorted(sims.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top classes similar to Internet Analytics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Internet analytics', 1.0000000000000002),\n",
       " ('A Network Tour of Data Science', 0.4474673072882506),\n",
       " ('Applied data analysis', 0.39831253596762267),\n",
       " ('Computational Social Media', 0.34260955208146177),\n",
       " ('Database systems', 0.3333640338430118),\n",
       " ('Digital education & learning analytics', 0.3124855139952114)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top classes similar to Internet Analytics:\")\n",
    "sims[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
